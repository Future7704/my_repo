---
title: "Hw3"
author: "Lai Wei"
date: "2024-07-04"
output: html_document
---

```{r}
gmp <- read.table("../data/gmp.dat")
gmp$pop <- round(gmp$gmp/gmp$pcgmp)
```

## 1

```{r}
plot_plm <- function(plm, ...) {
  n <- nrow(plm)
  Y0 <- plm$y0
  A <- plm$a
  
  F <- Vectorize(function(x, i) {
    return(Y0[i] * x^A[i])
  }, vectorize.args = "i")
  
  colors <- rainbow(n)
  
  curve(F(x, 1), col = colors[1], xlab = "pop", ylab = "pcgmp", ...)
  for (i in 2:n) {
    curve(F(x, i), col = colors[i], add = TRUE, ...)
  }
  
  legend("bottomright", legend = paste("y0=",Y0,", a=",A), col = colors, lty = 1, text.col = colors)
  
  invisible(TRUE)
}

plm <- data.frame("y0" = c(6611, 6611, 6611), "a" = c(1/8, 0.1, 0.15))
plot_plm(plm)
```

## 2

```{r}
mse <- function(parameter_vector, N = gmp$pop, Y = gmp$pcgmp){
  y0 <- parameter_vector[1]
  a <- parameter_vector[2]
  mse <- mean((y0 * N^a - Y)^2)
  return(mse)
}

mse(c(6611, 0.15))
mse(c(5000, 0.10))
```

## 3

```{r}
suppressWarnings(nlm(mse, c(y0 = 6611, a = 1/8)))
suppressWarnings(nlm(mse, c(y0 = 6611, a = 0.15)))
suppressWarnings(nlm(mse, c(y0 = 5000, a = 0.10)))
```

"Minimum" represents the minimum value found by the objective function `mse` in the optimization process; "estimate" represents the parameter estimate that makes the target function reach the minimum value.

## 4

```{r}
plm <- function(initial_y0, initial_a, N = gmp$pop, Y = gmp$pcgmp){
  result <- nlm(function(parameter_vector)mse(parameter_vector, N, Y), c(y0 = initial_y0, a = initial_a))
  final <- list("final_guess_y0" = result$estimate[1], "final_guess_a" = result$estimate[2], "final_value_MSE" = result$minimum)
  return(final)
}

suppressWarnings(plm(6611,0.15))
suppressWarnings(plm(5000,0.10))
```

Different optimization results are obtained from different initial values, because many optimization algorithms (such as `nlm()`) are based on gradient descent or similar methods, which are usually affected by the initial value, especially when the objective function has multiple local minimum values.
The former one has the lower MSE.

## 5
### a.

```{r}
mean(gmp$pcgmp)
n <- nrow(gmp)
s <- sd(gmp$pcgmp)
sem <- s / sqrt(n)
sem
```

### b.

```{r}
mean_pcgmp_except_i <- function(i){
  return(mean(gmp$pcgmp[-i]))
}
```

### c.

```{r}
jackknifed.means <- numeric(n)
for(omitted_point in 1:n){
  jackknifed.means[omitted_point] <- mean_pcgmp_except_i(omitted_point)
}
```

### d.

```{r}
jackknife_sem <- sqrt(((n-1)^2 / n)*var(jackknifed.means))
jackknife_sem
sem
```

They are the same.

## 6

```{r}


plm.jackknife <- function(initial_y0, initial_a, N = gmp$pop, Y = gmp$pcgmp){
  n <- nrow(gmp)
  jackknife_parameter <- matrix(0, nrow = 2, ncol = n)
  for(omitted_point in 1:n){
    jackknife_parameter[1,omitted_point] <- plm(initial_y0, initial_a, N = N[-omitted_point], Y = Y[-omitted_point])$final_guess_y0
    jackknife_parameter[2,omitted_point] <- plm(initial_y0, initial_a, N = N[-omitted_point], Y = Y[-omitted_point])$final_guess_a
  }
  jackknife_var <- ((n-1)^2 / n) * apply(jackknife_parameter, 1, var)
  
  return(sqrt(jackknife_var))
}

suppressWarnings(plm.jackknife(6611, 1/8))
```

## 7

```{r}
gmp2013 <- read.table('../data/gmp-2013.dat', header = T)
gmp2013$pop <- round(gmp2013$gmp/gmp2013$pcgmp)

suppressWarnings(plm(6611, 1/8, gmp2013$pop, gmp2013$pcgmp))
suppressWarnings(plm.jackknife(6611, 1/8, gmp2013$pop, gmp2013$pcgmp))
```

There's a subtle change in `final_guess_a`.










